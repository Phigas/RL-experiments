{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vizdoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vizdoom: RL platform, runs very quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd github & git clone https://github.com/mwydmuch/ViZDoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import game env\n",
    "from vizdoom import *\n",
    "# for random action\n",
    "import random\n",
    "# for sleeping\n",
    "import time\n",
    "# create action space for random actions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup game\n",
    "game = DoomGame()\n",
    "game.load_config('github/ViZDoom/scenarios/deadly_corridor.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple action space without double inputs\n",
    "actions = np.identity(7, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 10\n",
    "for episode in range(episodes):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        state = game.get_state()\n",
    "        img = state.screen_buffer\n",
    "        info = state.game_variables\n",
    "        reward = game.make_action(random.choice(actions)) # frame skip 4 -> get reward after 4 frames\n",
    "        print(reward)\n",
    "        time.sleep(1/50)\n",
    "    print('Total results:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wrap in Gym wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base class\n",
    "from gym import Env\n",
    "# import spaces\n",
    "from gym.spaces import Discrete, Box # Discrete is like range(), Box is like array\n",
    "# import opencv\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vizdoom env\n",
    "class ViZDoomGym(Env):\n",
    "    def __init__(self, render=False, config='github/ViZDoom/scenarios/deadly_corridor.cfg'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_nr = 7\n",
    "\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config(config)\n",
    "\n",
    "        self.game.set_window_visible(render)\n",
    "\n",
    "        self.game.init()\n",
    "\n",
    "        self.observation_space = Box(0, 255, shape=(100, 160, 1), dtype='uint8')\n",
    "        self.action_space = Discrete(self.action_nr)\n",
    "\n",
    "        self.damage_taken = 0\n",
    "        self.kill_count = 0\n",
    "        self.ammo = 52\n",
    "\n",
    "    def step(self, action):\n",
    "        actions = np.identity(self.action_nr, dtype='uint8')\n",
    "        movement_reward = self.game.make_action(actions[action])\n",
    "\n",
    "        reward = 0\n",
    "        if self.game.get_state(): # interesting line\n",
    "            state = self.game.get_state()\n",
    "            img = state.screen_buffer\n",
    "            img = self.grayscale(img)\n",
    "            \n",
    "            # reward shaping\n",
    "            game_variables = state.game_variables\n",
    "            health, damage_taken, kill_count, ammo = game_variables\n",
    "            \n",
    "            damage_taken_delta = - damage_taken + self.damage_taken # when hit gives negaitve value\n",
    "            self.damage_taken = damage_taken\n",
    "            kill_count_delta = kill_count - self.kill_count # when kills gives positive value\n",
    "            self.kill_count = kill_count\n",
    "            ammo_delta = ammo - self.ammo # when shoot give negative value\n",
    "            self.ammo = ammo\n",
    "            \n",
    "            reward = movement_reward + damage_taken_delta * 10 + kill_count_delta * 200 + ammo_delta * 5\n",
    "            \n",
    "            info = {}\n",
    "\n",
    "        else:\n",
    "            img = np.zeros(self.observation_space.shape)\n",
    "            info = {}\n",
    "\n",
    "        done = self.game.is_episode_finished()\n",
    "\n",
    "        return img, reward, done, info\n",
    "\n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "\n",
    "    def render():\n",
    "        pass # handled by vizdoom itself\n",
    "\n",
    "    def grayscale(self, observation):\n",
    "        img = cv.cvtColor(np.moveaxis(observation, 0, -1), cv.COLOR_BGR2GRAY)\n",
    "        # scale image down for performance\n",
    "        img = cv.resize(img, (160, 100), interpolation=cv.INTER_CUBIC)\n",
    "        img = np.reshape(img, (100, 160, 1)) # add one dimension\n",
    "        return img\n",
    "\n",
    "    def reset(self):\n",
    "        self.game.new_episode()\n",
    "        img = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ViZDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phiga\\miniconda3\\envs\\reinforcement\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# verify environment\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. Bitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. Klicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. Weitere Details finden Sie in Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "img = env.step(1)[0]\n",
    "plt.imshow(img, cmap='gray')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phiga\\miniconda3\\envs\\reinforcement\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './doom/train_corridor' # for model weights\n",
    "LOG_DIR = './doom/log_corridor' # for tf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=33000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the model with curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "env = ViZDoomGym(config='doom/corridor_schedule/deadly_corridor_s1.cfg')\n",
    "\n",
    "# old parameters\n",
    "# model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=4096)\n",
    "\n",
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.00001, n_steps=8192, clip_range=.1, gamma=.95, gae_lambda=.9)\n",
    "# also look at the definition of the metrics and reward if not training well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./doom/log_corridor\\PPO_5\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 895      |\n",
      "|    ep_rew_mean     | -85      |\n",
      "| time/              |          |\n",
      "|    fps             | 69       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 118      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 655          |\n",
      "|    ep_rew_mean          | 16.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027132803 |\n",
      "|    clip_fraction        | 0.0914       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -7.36e-05    |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 243          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 546          |\n",
      "|    ep_rew_mean          | 53           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 382          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027232233 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.00974      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 201          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 472          |\n",
      "|    ep_rew_mean          | 88.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 499          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019307069 |\n",
      "|    clip_fraction        | 0.0911       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.0351       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000674    |\n",
      "|    value_loss           | 3.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 422          |\n",
      "|    ep_rew_mean          | 108          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 627          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026714157 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.0741       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.36e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    value_loss           | 3.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 340          |\n",
      "|    ep_rew_mean          | 149          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 750          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024999478 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.122        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 4.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 316          |\n",
      "|    ep_rew_mean          | 184          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 878          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022815627 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.158        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 835          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000288    |\n",
      "|    value_loss           | 4.12e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 303         |\n",
      "|    ep_rew_mean          | 214         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1005        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002297331 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.000968   |\n",
      "|    value_loss           | 4.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 305          |\n",
      "|    ep_rew_mean          | 281          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 1134         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027792575 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000706    |\n",
      "|    value_loss           | 4.09e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 298          |\n",
      "|    ep_rew_mean          | 310          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1253         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026958415 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.14e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000751    |\n",
      "|    value_loss           | 4e+03        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 290         |\n",
      "|    ep_rew_mean          | 327         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1377        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002232708 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 674         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    value_loss           | 4.37e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 281          |\n",
      "|    ep_rew_mean          | 329          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1496         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027535376 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.236        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.17e+04     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    value_loss           | 4.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 261          |\n",
      "|    ep_rew_mean          | 323          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1619         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026113552 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.61e+03     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 4.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 258          |\n",
      "|    ep_rew_mean          | 356          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1745         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028626064 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.81        |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.74e+03     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 4.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 267          |\n",
      "|    ep_rew_mean          | 435          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1871         |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021733905 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.08e+03     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | 0.000178     |\n",
      "|    value_loss           | 4.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 275          |\n",
      "|    ep_rew_mean          | 477          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1995         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024205493 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 646          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    value_loss           | 4.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 269          |\n",
      "|    ep_rew_mean          | 523          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 2122         |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028752456 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 4.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 249          |\n",
      "|    ep_rew_mean          | 529          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 2244         |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023140558 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.69        |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.61e+03     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    value_loss           | 4.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 233          |\n",
      "|    ep_rew_mean          | 551          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 2371         |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035457416 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    value_loss           | 4.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 229          |\n",
      "|    ep_rew_mean          | 599          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 2491         |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030278745 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.254        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.09e+03     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000885    |\n",
      "|    value_loss           | 5.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 228          |\n",
      "|    ep_rew_mean          | 653          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 2613         |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029361728 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    value_loss           | 5.39e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 230          |\n",
      "|    ep_rew_mean          | 723          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2735         |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022317166 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.46e+03     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 5.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 212          |\n",
      "|    ep_rew_mean          | 727          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2854         |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022419472 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 981          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.000713    |\n",
      "|    value_loss           | 5.94e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 203         |\n",
      "|    ep_rew_mean          | 752         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2974        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002463601 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.22e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    value_loss           | 7.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 197         |\n",
      "|    ep_rew_mean          | 724         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 3103        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002732634 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.43e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    value_loss           | 6.57e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 751         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 3232        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002095439 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.37e+03    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 2.47e-05    |\n",
      "|    value_loss           | 5.61e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 182          |\n",
      "|    ep_rew_mean          | 714          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 3365         |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018382006 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.99e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000492    |\n",
      "|    value_loss           | 6.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 163          |\n",
      "|    ep_rew_mean          | 694          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 3501         |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027948273 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.06e+04     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    value_loss           | 6.66e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | 738         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 3638        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002406282 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.19e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.000293   |\n",
      "|    value_loss           | 7.43e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 167          |\n",
      "|    ep_rew_mean          | 761          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 3777         |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024345748 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.6e+03      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000946    |\n",
      "|    value_loss           | 6.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 160          |\n",
      "|    ep_rew_mean          | 767          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 3917         |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022178646 |\n",
      "|    clip_fraction        | 0.0873       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.956       |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.000656    |\n",
      "|    value_loss           | 6.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 159          |\n",
      "|    ep_rew_mean          | 773          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 4055         |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028391113 |\n",
      "|    clip_fraction        | 0.0988       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.957       |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -2.27e-05    |\n",
      "|    value_loss           | 7.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 165          |\n",
      "|    ep_rew_mean          | 807          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 4194         |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025242309 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.914       |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.51e+03     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000157    |\n",
      "|    value_loss           | 6.32e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 166          |\n",
      "|    ep_rew_mean          | 851          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 4332         |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016773362 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.909       |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -1.43e-05    |\n",
      "|    value_loss           | 6.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 163          |\n",
      "|    ep_rew_mean          | 831          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 4472         |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015865657 |\n",
      "|    clip_fraction        | 0.0763       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.851       |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.49e+03     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000532    |\n",
      "|    value_loss           | 6.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 159          |\n",
      "|    ep_rew_mean          | 829          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 4612         |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014413508 |\n",
      "|    clip_fraction        | 0.0837       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.865       |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.43e+03     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -7.25e-05    |\n",
      "|    value_loss           | 5.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 160          |\n",
      "|    ep_rew_mean          | 929          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 4751         |\n",
      "|    total_timesteps      | 303104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019763787 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.787       |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | 5.9e-05      |\n",
      "|    value_loss           | 7.3e+03      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x27db60cb880>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=33333, save_path=CHECKPOINT_DIR + '/s1')\n",
    "model.learn(total_timesteps=300000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x27d22c85360>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if model not loaded\n",
    "model.load(CHECKPOINT_DIR + '/s1' + '/best_model_299997.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./doom/log_corridor\\PPO_4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 512      |\n",
      "|    ep_rew_mean     | -18.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 68       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 119      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 522         |\n",
      "|    ep_rew_mean          | 22.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002562615 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -9.3e-06    |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 688         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    value_loss           | 2.93e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 512          |\n",
      "|    ep_rew_mean          | 73.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 403          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031352611 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0116       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 841          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 526          |\n",
      "|    ep_rew_mean          | 116          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 546          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032004807 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 380          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | 144          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 679          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029147628 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.0596       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 422          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    value_loss           | 2.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 467          |\n",
      "|    ep_rew_mean          | 193          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 811          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024293163 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.0704       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.86e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 414          |\n",
      "|    ep_rew_mean          | 250          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 942          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018220015 |\n",
      "|    clip_fraction        | 0.0932       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000778    |\n",
      "|    value_loss           | 3.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 337          |\n",
      "|    ep_rew_mean          | 284          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 1075         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032102242 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 652          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    value_loss           | 4.02e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 305         |\n",
      "|    ep_rew_mean          | 326         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1209        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001892928 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.52e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    value_loss           | 4.73e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 367         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1339        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002165481 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.000888   |\n",
      "|    value_loss           | 4.43e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 292         |\n",
      "|    ep_rew_mean          | 406         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1467        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002941295 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.26e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    value_loss           | 4.25e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 295          |\n",
      "|    ep_rew_mean          | 458          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1599         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024924304 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.196        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000943    |\n",
      "|    value_loss           | 3.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 290          |\n",
      "|    ep_rew_mean          | 494          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1728         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021021038 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00084     |\n",
      "|    value_loss           | 4.23e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x27df48ea8c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difficulty = 1\n",
    "# next step in curriculum\n",
    "env = ViZDoomGym(config=f'doom/corridor_schedule/deadly_corridor_s{difficulty}.cfg')\n",
    "model.set_env(env)\n",
    "callback = TrainAndLoggingCallback(check_freq=33333, save_path=CHECKPOINT_DIR + f'/s{difficulty}')\n",
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(CHECKPOINT_DIR + '/s1' + '/best_model_99999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ViZDoomGym(render=True, config='doom/corridor_schedule/deadly_corridor_s1.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward of episode 1 is -67.56155395507812\n",
      "Reward of episode 2 is 862.8701171875\n",
      "Reward of episode 3 is 169.54833984375\n",
      "Reward of episode 4 is 988.5729217529297\n",
      "Reward of episode 5 is 726.9300537109375\n"
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(1/50)\n",
    "        total_reward += reward\n",
    "    print(f'Reward of episode {episode+1} is {total_reward}')\n",
    "    time.sleep(2)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not perfoect performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reinforcement')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4984e7ba3fca0e09acc1abfa4e61dc59df22bf9db11b60a1a72c49fd6cc05221"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
