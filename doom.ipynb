{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vizdoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vizdoom: RL platform, runs very quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd github & git clone https://github.com/mwydmuch/ViZDoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import game env\n",
    "from vizdoom import *\n",
    "# for random action\n",
    "import random\n",
    "# for sleeping\n",
    "import time\n",
    "# create action space for random actions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup game\n",
    "game = DoomGame()\n",
    "game.load_config('github/ViZDoom/scenarios/basic.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple action space without double inputs\n",
    "actions = np.identity(3, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 10\n",
    "for episode in range(episodes):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        state = game.get_state()\n",
    "        img = state.screen_buffer\n",
    "        info = state.game_variables\n",
    "        reward = game.make_action(random.choice(actions), 4) # frame skip 4 -> get reward after 4 frames\n",
    "        print(reward)\n",
    "        time.sleep(1/50)\n",
    "    print('Total results:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wrap in Gym wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base class\n",
    "from gym import Env\n",
    "# import spaces\n",
    "from gym.spaces import Discrete, Box # Discrete is like range(), Box is like array\n",
    "# import opencv\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vizdoom env\n",
    "class ViZDoomGym(Env):\n",
    "    def __init__(self, render=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config('github/ViZDoom/scenarios/basic.cfg')\n",
    "\n",
    "        self.game.set_window_visible(render)\n",
    "\n",
    "        self.game.init()\n",
    "\n",
    "        self.observation_space = Box(0, 255, shape=(100, 160, 1), dtype='uint8')\n",
    "        self.action_space = Discrete(3)\n",
    "\n",
    "    def step(self, action):\n",
    "        actions = np.identity(3, dtype='uint8')\n",
    "        reward = self.game.make_action(actions[action])\n",
    "\n",
    "        if self.game.get_state(): # interesting line\n",
    "            state = self.game.get_state()\n",
    "            img = state.screen_buffer\n",
    "            img = self.grayscale(img)\n",
    "            ammo = state.game_variables[0]\n",
    "            info = {'ammo': ammo}\n",
    "        else:\n",
    "            img = np.zeros(self.observation_space.shape)\n",
    "            info = {}\n",
    "\n",
    "        done = self.game.is_episode_finished()\n",
    "\n",
    "        return img, reward, done, info\n",
    "\n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.game.close()\n",
    "        super().__del__()\n",
    "\n",
    "    def render():\n",
    "        pass # handled by vizdoom itself\n",
    "\n",
    "    def grayscale(self, observation):\n",
    "        img = cv.cvtColor(np.moveaxis(observation, 0, -1), cv.COLOR_BGR2GRAY)\n",
    "        # scale image down for performance\n",
    "        img = cv.resize(img, (160, 100), interpolation=cv.INTER_CUBIC)\n",
    "        img = np.reshape(img, (100, 160, 1)) # add one dimension\n",
    "        return img\n",
    "\n",
    "    def reset(self):\n",
    "        self.game.new_episode()\n",
    "        img = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ViZDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify environment\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "img = env.step(1)[0]\n",
    "plt.imshow(img, cmap='gray')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phiga\\miniconda3\\envs\\reinforcement\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './doom/train_basic' # for model weights\n",
    "LOG_DIR = './doom/log_basic' # for tf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=33000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ViZDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./doom/log_basic\\PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 144      |\n",
      "|    ep_rew_mean     | -117     |\n",
      "| time/              |          |\n",
      "|    fps             | 73       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 118         |\n",
      "|    ep_rew_mean          | -73.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010898388 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.000135   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.000237    |\n",
      "|    value_loss           | 358         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 120         |\n",
      "|    ep_rew_mean          | -80.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024161477 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 79.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | 0.000451    |\n",
      "|    value_loss           | 343         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 108         |\n",
      "|    ep_rew_mean          | -62         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014759716 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 74.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 0.00395     |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | -52.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 169        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01454428 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.722      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 181        |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | 0.00717    |\n",
      "|    value_loss           | 352        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 85.2        |\n",
      "|    ep_rew_mean          | -28         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046384126 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 62.8        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.5       |\n",
      "|    ep_rew_mean          | -15.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 240        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02621598 |\n",
      "|    clip_fraction        | 0.402      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0.86       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 53.1       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | 0.015      |\n",
      "|    value_loss           | 166        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 82.8       |\n",
      "|    ep_rew_mean          | -24.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01149895 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0.846      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 74.4       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | 6.52e-05   |\n",
      "|    value_loss           | 227        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 87.5        |\n",
      "|    ep_rew_mean          | -31.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012958825 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 99.5        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.00221     |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96.1        |\n",
      "|    ep_rew_mean          | -44.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017506052 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.942      |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.00546     |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 101          |\n",
      "|    ep_rew_mean          | -53.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 380          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077261655 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.942       |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 0.00329      |\n",
      "|    value_loss           | 274          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 99.8        |\n",
      "|    ep_rew_mean          | -50.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004179091 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 77.3        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | 0.00458     |\n",
      "|    value_loss           | 305         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.8        |\n",
      "|    ep_rew_mean          | -48.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013089722 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 0.000713    |\n",
      "|    value_loss           | 546         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 74.8       |\n",
      "|    ep_rew_mean          | -9.45      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 489        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02143041 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0.758      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 422        |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | 0.00346    |\n",
      "|    value_loss           | 463        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 55.2        |\n",
      "|    ep_rew_mean          | 20.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014922725 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.00195     |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 52.8        |\n",
      "|    ep_rew_mean          | 26.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 560         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010804562 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015898993 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 233         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000137   |\n",
      "|    value_loss           | 355         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 52.2        |\n",
      "|    ep_rew_mean          | 29.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 634         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018421594 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 35.5       |\n",
      "|    ep_rew_mean          | 57.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 668        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04821147 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.968     |\n",
      "|    explained_variance   | 0.785      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 126        |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | 0.00951    |\n",
      "|    value_loss           | 383        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.5       |\n",
      "|    ep_rew_mean          | 63.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 705        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02027651 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.922     |\n",
      "|    explained_variance   | 0.884      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 88         |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | 0.00108    |\n",
      "|    value_loss           | 285        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.6        |\n",
      "|    ep_rew_mean          | 68.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 743         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025466692 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.903      |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 83.7        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.9        |\n",
      "|    ep_rew_mean          | 72.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027931144 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00146    |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 63.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 815         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023655396 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.82       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.000616   |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.6        |\n",
      "|    ep_rew_mean          | 54.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 851         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010906162 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.796      |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 87.4        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00143     |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 23.7       |\n",
      "|    ep_rew_mean          | 71.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 890        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01681574 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.8       |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 54.4       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | 0.000757   |\n",
      "|    value_loss           | 151        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.9        |\n",
      "|    ep_rew_mean          | 77.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 929         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019548677 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.764      |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -8.78e-05   |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.6        |\n",
      "|    ep_rew_mean          | 81.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 963         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018782932 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 83.7        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.000961   |\n",
      "|    value_loss           | 246         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.9        |\n",
      "|    ep_rew_mean          | 83.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1000        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029378023 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.655      |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.00731     |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.9        |\n",
      "|    ep_rew_mean          | 81.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1039        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036678486 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.591      |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 86.4        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.0112      |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.6        |\n",
      "|    ep_rew_mean          | 83          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 1078        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035421893 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.0269      |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 15.3       |\n",
      "|    ep_rew_mean          | 84.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 1113       |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02029404 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.496     |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 37.9       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | 0.00596    |\n",
      "|    value_loss           | 175        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.1        |\n",
      "|    ep_rew_mean          | 81.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 1150        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018376645 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.446      |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 56.7        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 15.6      |\n",
      "|    ep_rew_mean          | 84.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 56        |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 1189      |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0336672 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.427    |\n",
      "|    explained_variance   | 0.716     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 47.5      |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | 0.0078    |\n",
      "|    value_loss           | 112       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.1        |\n",
      "|    ep_rew_mean          | 72.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1228        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037319668 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.377      |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.00434     |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.6        |\n",
      "|    ep_rew_mean          | 83.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1262        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042095885 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.617      |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 49.9        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.0203      |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.8        |\n",
      "|    ep_rew_mean          | 87.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1299        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025885832 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.367      |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.0102      |\n",
      "|    value_loss           | 77.4        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 16.7     |\n",
      "|    ep_rew_mean          | 81.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 56       |\n",
      "|    iterations           | 37       |\n",
      "|    time_elapsed         | 1339     |\n",
      "|    total_timesteps      | 75776    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.039084 |\n",
      "|    clip_fraction        | 0.182    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.441   |\n",
      "|    explained_variance   | 0.721    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 28.3     |\n",
      "|    n_updates            | 360      |\n",
      "|    policy_gradient_loss | 0.017    |\n",
      "|    value_loss           | 67.3     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.4        |\n",
      "|    ep_rew_mean          | 84.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1378        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025024254 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.468      |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.4        |\n",
      "|    ep_rew_mean          | 80.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1416        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015440313 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 81.7        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.000773    |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.8         |\n",
      "|    ep_rew_mean          | 85.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 1448         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118162595 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.374       |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | 0.00817      |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 17         |\n",
      "|    ep_rew_mean          | 82.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 1478       |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02512493 |\n",
      "|    clip_fraction        | 0.0849     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.281     |\n",
      "|    explained_variance   | 0.79       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 65.5       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.00394    |\n",
      "|    value_loss           | 114        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 16.9       |\n",
      "|    ep_rew_mean          | 81.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 1514       |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01694686 |\n",
      "|    clip_fraction        | 0.0931     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.292     |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 55.9       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | 0.00105    |\n",
      "|    value_loss           | 153        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 13.9       |\n",
      "|    ep_rew_mean          | 86.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 1547       |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02026711 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.353     |\n",
      "|    explained_variance   | 0.882      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 25.5       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | 0.0133     |\n",
      "|    value_loss           | 63.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.1        |\n",
      "|    ep_rew_mean          | 87.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1576        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021133456 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.221      |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.0026      |\n",
      "|    value_loss           | 75.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.9        |\n",
      "|    ep_rew_mean          | 89          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1613        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024930682 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.199      |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.000507   |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 13.6       |\n",
      "|    ep_rew_mean          | 87.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 1646       |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02457184 |\n",
      "|    clip_fraction        | 0.0866     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.243     |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 15.4       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | 0.0101     |\n",
      "|    value_loss           | 40.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.1        |\n",
      "|    ep_rew_mean          | 84.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1675        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047451194 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 58.9        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.0231      |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.8        |\n",
      "|    ep_rew_mean          | 86.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1713        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015461392 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.206      |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00194     |\n",
      "|    value_loss           | 78.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.7        |\n",
      "|    ep_rew_mean          | 86          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1745        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011947999 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.163      |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.00364     |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x19bab8d1ab0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(CHECKPOINT_DIR + '/best_model_99000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ViZDoomGym.__del__ at 0x0000019BAB89D630>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\phiga\\AppData\\Local\\Temp\\ipykernel_16636\\2583540790.py\", line 39, in __del__\n",
      "AttributeError: 'super' object has no attribute '__del__'\n"
     ]
    }
   ],
   "source": [
    "env = ViZDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phiga\\miniconda3\\envs\\reinforcement\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.92"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ViZDoomIsNotRunningException",
     "evalue": "Controlled ViZDoom instance is not running or not ready.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mViZDoomIsNotRunningException\u001b[0m              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\phiga\\OneDrive\\Zwischenspeicher\\Projects maker\\Programming\\reinforcement learning\\doom.ipynb Zelle 34\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phiga/OneDrive/Zwischenspeicher/Projects%20maker/Programming/reinforcement%20learning/doom.ipynb#ch0000047?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m episode \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/phiga/OneDrive/Zwischenspeicher/Projects%20maker/Programming/reinforcement%20learning/doom.ipynb#ch0000047?line=1'>2</a>\u001b[0m     obs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mreset()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phiga/OneDrive/Zwischenspeicher/Projects%20maker/Programming/reinforcement%20learning/doom.ipynb#ch0000047?line=2'>3</a>\u001b[0m     done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phiga/OneDrive/Zwischenspeicher/Projects%20maker/Programming/reinforcement%20learning/doom.ipynb#ch0000047?line=3'>4</a>\u001b[0m     total_reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\phiga\\OneDrive\\Zwischenspeicher\\Projects maker\\Programming\\reinforcement learning\\doom.ipynb Zelle 34\u001b[0m in \u001b[0;36mViZDoomGym.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phiga/OneDrive/Zwischenspeicher/Projects%20maker/Programming/reinforcement%20learning/doom.ipynb#ch0000047?line=50'>51</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/phiga/OneDrive/Zwischenspeicher/Projects%20maker/Programming/reinforcement%20learning/doom.ipynb#ch0000047?line=51'>52</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgame\u001b[39m.\u001b[39;49mnew_episode()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phiga/OneDrive/Zwischenspeicher/Projects%20maker/Programming/reinforcement%20learning/doom.ipynb#ch0000047?line=52'>53</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame\u001b[39m.\u001b[39mget_state()\u001b[39m.\u001b[39mscreen_buffer\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phiga/OneDrive/Zwischenspeicher/Projects%20maker/Programming/reinforcement%20learning/doom.ipynb#ch0000047?line=53'>54</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrayscale(img)\n",
      "\u001b[1;31mViZDoomIsNotRunningException\u001b[0m: Controlled ViZDoom instance is not running or not ready."
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(1/50)\n",
    "        total_reward += reward\n",
    "    print(f'Reward of episode {episode+1} is {total_reward}')\n",
    "    time.sleep(2)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not perfoect performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reinforcement')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4984e7ba3fca0e09acc1abfa4e61dc59df22bf9db11b60a1a72c49fd6cc05221"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
