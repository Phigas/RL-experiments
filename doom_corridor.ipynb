{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vizdoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vizdoom: RL platform, runs very quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd github & git clone https://github.com/mwydmuch/ViZDoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import game env\n",
    "from vizdoom import *\n",
    "# for random action\n",
    "import random\n",
    "# for sleeping\n",
    "import time\n",
    "# create action space for random actions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup game\n",
    "game = DoomGame()\n",
    "game.load_config('github/ViZDoom/scenarios/deadly_corridor.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple action space without double inputs\n",
    "actions = np.identity(7, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.022430419921875\n",
      "-0.002105712890625\n",
      "-0.001922607421875\n",
      "-0.7830047607421875\n",
      "-1.4908599853515625\n",
      "-2.132354736328125\n",
      "-8.859329223632812\n",
      "-2.5012664794921875\n",
      "-0.227203369140625\n",
      "-0.022430419921875\n",
      "0.0\n",
      "-0.0013275146484375\n",
      "0.7564544677734375\n",
      "-0.3112640380859375\n",
      "0.498779296875\n",
      "-0.3288726806640625\n",
      "-0.2980499267578125\n",
      "0.5096588134765625\n",
      "0.5072784423828125\n",
      "0.459716796875\n",
      "-0.3631744384765625\n",
      "-0.283721923828125\n",
      "-0.2571258544921875\n",
      "-0.8586273193359375\n",
      "0.0\n",
      "0.0\n",
      "0.04541015625\n",
      "0.0411529541015625\n",
      "-0.0950927734375\n",
      "0.0683441162109375\n",
      "0.0619354248046875\n",
      "0.056121826171875\n",
      "0.11920166015625\n",
      "-0.3078155517578125\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0683441162109375\n",
      "-0.0064239501953125\n",
      "0.0625152587890625\n",
      "0.056640625\n",
      "0.826690673828125\n",
      "0.6579437255859375\n",
      "0.59625244140625\n",
      "0.54034423828125\n",
      "0.48968505859375\n",
      "0.4662017822265625\n",
      "0.400054931640625\n",
      "0.340118408203125\n",
      "1.0890960693359375\n",
      "1.0094146728515625\n",
      "0.9147796630859375\n",
      "0.829010009765625\n",
      "-0.02960205078125\n",
      "-0.0268402099609375\n",
      "-0.0243377685546875\n",
      "-0.022064208984375\n",
      "0.7612457275390625\n",
      "0.6898651123046875\n",
      "0.62518310546875\n",
      "-0.214691162109375\n",
      "-0.1945648193359375\n",
      "-0.95758056640625\n",
      "-0.8406982421875\n",
      "-0.190765380859375\n",
      "-0.172882080078125\n",
      "0.6035614013671875\n",
      "0.2874298095703125\n",
      "-0.5203857421875\n",
      "0.3092498779296875\n",
      "0.3032379150390625\n",
      "-99.72520446777344\n",
      "Total results: -106.97824096679688\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.78125\n",
      "-0.7080078125\n",
      "-0.641632080078125\n",
      "-1.36273193359375\n",
      "-1.2349853515625\n",
      "-9.507461547851562\n",
      "-1.494720458984375\n",
      "0.0\n",
      "-0.0431976318359375\n",
      "-0.205047607421875\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0459747314453125\n",
      "0.0876312255859375\n",
      "0.076904296875\n",
      "0.8358917236328125\n",
      "0.7575225830078125\n",
      "0.686492919921875\n",
      "0.62213134765625\n",
      "1.3416595458984375\n",
      "1.2158660888671875\n",
      "1.10186767578125\n",
      "0.998565673828125\n",
      "1.676910400390625\n",
      "1.5196990966796875\n",
      "1.5144805908203125\n",
      "1.32958984375\n",
      "-0.1598358154296875\n",
      "-0.1448516845703125\n",
      "-0.13128662109375\n",
      "-0.118988037109375\n",
      "0.6553192138671875\n",
      "1.357025146484375\n",
      "1.992950439453125\n",
      "2.5692596435546875\n",
      "2.4882049560546875\n",
      "-97.74507141113281\n",
      "Total results: -91.40512084960938\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.78125\n",
      "0.7080078125\n",
      "0.641632080078125\n",
      "0.5814666748046875\n",
      "0.526947021484375\n",
      "0.45452880859375\n",
      "0.3889007568359375\n",
      "-0.428436279296875\n",
      "0.392578125\n",
      "0.3787689208984375\n",
      "0.3432464599609375\n",
      "-0.470184326171875\n",
      "-0.426116943359375\n",
      "-0.3631744384765625\n",
      "-0.329132080078125\n",
      "-0.29827880859375\n",
      "-0.247894287109375\n",
      "-0.2246551513671875\n",
      "-0.9844818115234375\n",
      "-1.6730804443359375\n",
      "-1.538665771484375\n",
      "-1.4168548583984375\n",
      "-1.284027099609375\n",
      "-1.1636505126953125\n",
      "-1.8358154296875\n",
      "-1.6637115478515625\n",
      "-1.530181884765625\n",
      "-2.1676177978515625\n",
      "-1.986846923828125\n",
      "-1.01971435546875\n",
      "-0.0915374755859375\n",
      "0.0\n",
      "0.0\n",
      "0.7568206787109375\n",
      "-0.46173095703125\n",
      "-0.310882568359375\n",
      "0.0\n",
      "0.0\n",
      "0.022430419921875\n",
      "-0.039886474609375\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.7797698974609375\n",
      "0.7520751953125\n",
      "0.6815643310546875\n",
      "0.5952301025390625\n",
      "0.5169830322265625\n",
      "0.468505859375\n",
      "1.204345703125\n",
      "1.1368408203125\n",
      "1.0756683349609375\n",
      "0.195037841796875\n",
      "0.1767425537109375\n",
      "0.1601715087890625\n",
      "0.9249114990234375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\phiga\\Documents\\GitHub\\RL-experminents\\doom_corridor.ipynb Zelle 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000007?line=7'>8</a>\u001b[0m     reward \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mmake_action(random\u001b[39m.\u001b[39mchoice(actions)) \u001b[39m# frame skip 4 -> get reward after 4 frames\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000007?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(reward)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000007?line=9'>10</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000007?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTotal results:\u001b[39m\u001b[39m'\u001b[39m, game\u001b[39m.\u001b[39mget_total_reward())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000007?line=11'>12</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(episodes):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        state = game.get_state()\n",
    "        img = state.screen_buffer\n",
    "        info = state.game_variables\n",
    "        reward = game.make_action(random.choice(actions)) # frame skip 4 -> get reward after 4 frames\n",
    "        print(reward)\n",
    "        time.sleep(1/10)\n",
    "    print('Total results:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wrap in Gym wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base class\n",
    "from gym import Env\n",
    "# import spaces\n",
    "from gym.spaces import Discrete, Box # Discrete is like range(), Box is like array\n",
    "# import opencv\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vizdoom env\n",
    "class ViZDoomGym(Env):\n",
    "    def __init__(self, render=False, config='github/ViZDoom/scenarios/deadly_corridor.cfg'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_nr = 7\n",
    "\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config(config)\n",
    "\n",
    "        self.game.set_window_visible(render)\n",
    "\n",
    "        self.game.init()\n",
    "\n",
    "        self.observation_space = Box(0, 255, shape=(100, 160, 1), dtype='uint8')\n",
    "        self.action_space = Discrete(self.action_nr)\n",
    "\n",
    "        self.damage_taken = 0\n",
    "        self.kill_count = 0\n",
    "        self.ammo = 52\n",
    "\n",
    "    def step(self, action):\n",
    "        actions = np.identity(self.action_nr, dtype='uint8')\n",
    "        movement_reward = self.game.make_action(actions[action])\n",
    "\n",
    "        reward = 0\n",
    "        if self.game.get_state(): # interesting line\n",
    "            state = self.game.get_state()\n",
    "            img = state.screen_buffer\n",
    "            img = self.grayscale(img)\n",
    "            \n",
    "            # reward shaping\n",
    "            game_variables = state.game_variables\n",
    "            health, damage_taken, kill_count, ammo = game_variables\n",
    "            \n",
    "            damage_taken_delta = - damage_taken + self.damage_taken # when hit gives negaitve value\n",
    "            self.damage_taken = damage_taken\n",
    "            kill_count_delta = kill_count - self.kill_count # when kills gives positive value\n",
    "            self.kill_count = kill_count\n",
    "            ammo_delta = ammo - self.ammo # when shoot give negative value\n",
    "            self.ammo = ammo\n",
    "                        \n",
    "            reward = movement_reward + damage_taken_delta * 5 + kill_count_delta * 250 + ammo_delta * 5\n",
    "            \n",
    "            info = {}\n",
    "\n",
    "        else:\n",
    "            img = np.zeros(self.observation_space.shape)\n",
    "            info = {}\n",
    "\n",
    "        done = self.game.is_episode_finished()\n",
    "\n",
    "        return img, reward, done, info\n",
    "\n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "\n",
    "    def render():\n",
    "        pass # handled by vizdoom itself\n",
    "\n",
    "    def grayscale(self, observation):\n",
    "        img = cv.cvtColor(np.moveaxis(observation, 0, -1), cv.COLOR_BGR2GRAY)\n",
    "        # scale image down for performance\n",
    "        img = cv.resize(img, (160, 100), interpolation=cv.INTER_CUBIC)\n",
    "        img = np.reshape(img, (100, 160, 1)) # add one dimension\n",
    "        return img\n",
    "\n",
    "    def reset(self):\n",
    "        self.game.new_episode()\n",
    "        img = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ViZDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phiga\\miniconda3\\envs\\reinforcement\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# verify environment\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. Bitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. Klicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. Weitere Details finden Sie in Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "img = env.step(1)[0]\n",
    "plt.imshow(img, cmap='gray')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './doom/train_corridor' # for model weights\n",
    "LOG_DIR = './doom/log_corridor' # for tf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=33000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the model with curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phiga\\miniconda3\\envs\\reinforcement\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "env = ViZDoomGym(config='doom/corridor_schedule/deadly_corridor_s1.cfg')\n",
    "\n",
    "# old parameters\n",
    "# model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=4096)\n",
    "\n",
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.00001, n_steps=8192, clip_range=.1, gamma=.95, gae_lambda=.9)\n",
    "# also look at the definition of the metrics and reward if not training well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./doom/log_corridor\\PPO_5\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 895      |\n",
      "|    ep_rew_mean     | -85      |\n",
      "| time/              |          |\n",
      "|    fps             | 69       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 118      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 655          |\n",
      "|    ep_rew_mean          | 16.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027132803 |\n",
      "|    clip_fraction        | 0.0914       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -7.36e-05    |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 243          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 546          |\n",
      "|    ep_rew_mean          | 53           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 382          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027232233 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.00974      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 201          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 472          |\n",
      "|    ep_rew_mean          | 88.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 499          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019307069 |\n",
      "|    clip_fraction        | 0.0911       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.0351       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000674    |\n",
      "|    value_loss           | 3.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 422          |\n",
      "|    ep_rew_mean          | 108          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 627          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026714157 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.0741       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.36e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    value_loss           | 3.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 340          |\n",
      "|    ep_rew_mean          | 149          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 750          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024999478 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.122        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 4.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 316          |\n",
      "|    ep_rew_mean          | 184          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 878          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022815627 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.158        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 835          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000288    |\n",
      "|    value_loss           | 4.12e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 303         |\n",
      "|    ep_rew_mean          | 214         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1005        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002297331 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.000968   |\n",
      "|    value_loss           | 4.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 305          |\n",
      "|    ep_rew_mean          | 281          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 1134         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027792575 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000706    |\n",
      "|    value_loss           | 4.09e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 298          |\n",
      "|    ep_rew_mean          | 310          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1253         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026958415 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.14e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000751    |\n",
      "|    value_loss           | 4e+03        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 290         |\n",
      "|    ep_rew_mean          | 327         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1377        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002232708 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 674         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    value_loss           | 4.37e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 281          |\n",
      "|    ep_rew_mean          | 329          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1496         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027535376 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.236        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.17e+04     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    value_loss           | 4.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 261          |\n",
      "|    ep_rew_mean          | 323          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1619         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026113552 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.61e+03     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 4.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 258          |\n",
      "|    ep_rew_mean          | 356          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1745         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028626064 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.81        |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.74e+03     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 4.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 267          |\n",
      "|    ep_rew_mean          | 435          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1871         |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021733905 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.08e+03     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | 0.000178     |\n",
      "|    value_loss           | 4.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 275          |\n",
      "|    ep_rew_mean          | 477          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1995         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024205493 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 646          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    value_loss           | 4.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 269          |\n",
      "|    ep_rew_mean          | 523          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 2122         |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028752456 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 4.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 249          |\n",
      "|    ep_rew_mean          | 529          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 2244         |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023140558 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.69        |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.61e+03     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    value_loss           | 4.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 233          |\n",
      "|    ep_rew_mean          | 551          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 2371         |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035457416 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    value_loss           | 4.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 229          |\n",
      "|    ep_rew_mean          | 599          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 2491         |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030278745 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.254        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.09e+03     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000885    |\n",
      "|    value_loss           | 5.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 228          |\n",
      "|    ep_rew_mean          | 653          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 2613         |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029361728 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    value_loss           | 5.39e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 230          |\n",
      "|    ep_rew_mean          | 723          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2735         |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022317166 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.46e+03     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 5.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 212          |\n",
      "|    ep_rew_mean          | 727          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2854         |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022419472 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 981          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.000713    |\n",
      "|    value_loss           | 5.94e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 203         |\n",
      "|    ep_rew_mean          | 752         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2974        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002463601 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.22e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    value_loss           | 7.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 197         |\n",
      "|    ep_rew_mean          | 724         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 3103        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002732634 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.43e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    value_loss           | 6.57e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 751         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 3232        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002095439 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.37e+03    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 2.47e-05    |\n",
      "|    value_loss           | 5.61e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 182          |\n",
      "|    ep_rew_mean          | 714          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 3365         |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018382006 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.99e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000492    |\n",
      "|    value_loss           | 6.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 163          |\n",
      "|    ep_rew_mean          | 694          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 3501         |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027948273 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.06e+04     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    value_loss           | 6.66e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | 738         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 3638        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002406282 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.19e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.000293   |\n",
      "|    value_loss           | 7.43e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 167          |\n",
      "|    ep_rew_mean          | 761          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 3777         |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024345748 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.6e+03      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000946    |\n",
      "|    value_loss           | 6.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 160          |\n",
      "|    ep_rew_mean          | 767          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 3917         |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022178646 |\n",
      "|    clip_fraction        | 0.0873       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.956       |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.000656    |\n",
      "|    value_loss           | 6.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 159          |\n",
      "|    ep_rew_mean          | 773          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 4055         |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028391113 |\n",
      "|    clip_fraction        | 0.0988       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.957       |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -2.27e-05    |\n",
      "|    value_loss           | 7.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 165          |\n",
      "|    ep_rew_mean          | 807          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 4194         |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025242309 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.914       |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.51e+03     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000157    |\n",
      "|    value_loss           | 6.32e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 166          |\n",
      "|    ep_rew_mean          | 851          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 4332         |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016773362 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.909       |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -1.43e-05    |\n",
      "|    value_loss           | 6.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 163          |\n",
      "|    ep_rew_mean          | 831          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 4472         |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015865657 |\n",
      "|    clip_fraction        | 0.0763       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.851       |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.49e+03     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000532    |\n",
      "|    value_loss           | 6.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 159          |\n",
      "|    ep_rew_mean          | 829          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 4612         |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014413508 |\n",
      "|    clip_fraction        | 0.0837       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.865       |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.43e+03     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -7.25e-05    |\n",
      "|    value_loss           | 5.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 160          |\n",
      "|    ep_rew_mean          | 929          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 4751         |\n",
      "|    total_timesteps      | 303104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019763787 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.787       |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | 5.9e-05      |\n",
      "|    value_loss           | 7.3e+03      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x27db60cb880>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=33333, save_path=CHECKPOINT_DIR + '/s1')\n",
    "model.learn(total_timesteps=300000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./doom/log_corridor\\PPO_11\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 56.4     |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    fps             | 77       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 55.3       |\n",
      "|    ep_rew_mean          | 251        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 66         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 246        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01737317 |\n",
      "|    clip_fraction        | 0.0307     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.146      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 1.12e+03   |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | -4.29e-05  |\n",
      "|    value_loss           | 3.74e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 55.6       |\n",
      "|    ep_rew_mean          | 235        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 387        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02221816 |\n",
      "|    clip_fraction        | 0.0354     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.0835    |\n",
      "|    explained_variance   | 0.586      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 1.15e+03   |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.00247   |\n",
      "|    value_loss           | 3.16e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 56.2         |\n",
      "|    ep_rew_mean          | 240          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 526          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009927667 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.19        |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 992          |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | 0.000532     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 55.7         |\n",
      "|    ep_rew_mean          | 245          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 667          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041668434 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.176       |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 945          |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | 0.00123      |\n",
      "|    value_loss           | 2.59e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 57            |\n",
      "|    ep_rew_mean          | 251           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 60            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 814           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031109835 |\n",
      "|    clip_fraction        | 0.0127        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.118        |\n",
      "|    explained_variance   | 0.673         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.57e+03      |\n",
      "|    n_updates            | 650           |\n",
      "|    policy_gradient_loss | 0.000479      |\n",
      "|    value_loss           | 2.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 56.8          |\n",
      "|    ep_rew_mean          | 254           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 59            |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 959           |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092302694 |\n",
      "|    clip_fraction        | 0.0146        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.122        |\n",
      "|    explained_variance   | 0.686         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.19e+03      |\n",
      "|    n_updates            | 660           |\n",
      "|    policy_gradient_loss | 0.000564      |\n",
      "|    value_loss           | 2.91e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 56.5         |\n",
      "|    ep_rew_mean          | 250          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 1102         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006602629 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.105       |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | 0.000834     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 57.7        |\n",
      "|    ep_rew_mean          | 255         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1250        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002564255 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.129      |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | 0.00115     |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 59.2          |\n",
      "|    ep_rew_mean          | 260           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 1392          |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077700824 |\n",
      "|    clip_fraction        | 0.0213        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.153        |\n",
      "|    explained_variance   | 0.676         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 916           |\n",
      "|    n_updates            | 690           |\n",
      "|    policy_gradient_loss | 0.00108       |\n",
      "|    value_loss           | 3e+03         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 58.4         |\n",
      "|    ep_rew_mean          | 253          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1531         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009500934 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.153       |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 873          |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | 0.00107      |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 61           |\n",
      "|    ep_rew_mean          | 273          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1667         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016241837 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.176       |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | 0.000693     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 60.7          |\n",
      "|    ep_rew_mean          | 265           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 1814          |\n",
      "|    total_timesteps      | 106496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071032526 |\n",
      "|    clip_fraction        | 0.03          |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.185        |\n",
      "|    explained_variance   | 0.724         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 795           |\n",
      "|    n_updates            | 720           |\n",
      "|    policy_gradient_loss | 0.00119       |\n",
      "|    value_loss           | 2.85e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 54.6        |\n",
      "|    ep_rew_mean          | 223         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1960        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001648067 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.205      |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.00118     |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 57.8        |\n",
      "|    ep_rew_mean          | 249         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 2100        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004372119 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.171      |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | 0.000998    |\n",
      "|    value_loss           | 2.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 58           |\n",
      "|    ep_rew_mean          | 256          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 2242         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009517347 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.131       |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 901          |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | 0.000959     |\n",
      "|    value_loss           | 2.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 59.2         |\n",
      "|    ep_rew_mean          | 272          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 2386         |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006644315 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.129       |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 912          |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | 0.00124      |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 53            |\n",
      "|    ep_rew_mean          | 219           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 2523          |\n",
      "|    total_timesteps      | 147456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037675817 |\n",
      "|    clip_fraction        | 0.0192        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.132        |\n",
      "|    explained_variance   | 0.691         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.52e+03      |\n",
      "|    n_updates            | 770           |\n",
      "|    policy_gradient_loss | 0.000387      |\n",
      "|    value_loss           | 2.99e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 61.4          |\n",
      "|    ep_rew_mean          | 289           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 2665          |\n",
      "|    total_timesteps      | 155648        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042251678 |\n",
      "|    clip_fraction        | 0.0186        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.125        |\n",
      "|    explained_variance   | 0.748         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.32e+03      |\n",
      "|    n_updates            | 780           |\n",
      "|    policy_gradient_loss | 0.000751      |\n",
      "|    value_loss           | 2.49e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 56.1          |\n",
      "|    ep_rew_mean          | 245           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 2809          |\n",
      "|    total_timesteps      | 163840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044662764 |\n",
      "|    clip_fraction        | 0.0181        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.119        |\n",
      "|    explained_variance   | 0.701         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 870           |\n",
      "|    n_updates            | 790           |\n",
      "|    policy_gradient_loss | 0.000496      |\n",
      "|    value_loss           | 2.87e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 57.4         |\n",
      "|    ep_rew_mean          | 262          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 2957         |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007545933 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.107       |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 784          |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | 0.00105      |\n",
      "|    value_loss           | 2.6e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 52.6          |\n",
      "|    ep_rew_mean          | 216           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 3097          |\n",
      "|    total_timesteps      | 180224        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090056926 |\n",
      "|    clip_fraction        | 0.0121        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.0918       |\n",
      "|    explained_variance   | 0.713         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.8e+03       |\n",
      "|    n_updates            | 810           |\n",
      "|    policy_gradient_loss | 0.00041       |\n",
      "|    value_loss           | 2.68e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 56.4          |\n",
      "|    ep_rew_mean          | 248           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 3244          |\n",
      "|    total_timesteps      | 188416        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075736124 |\n",
      "|    clip_fraction        | 0.0131        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.0927       |\n",
      "|    explained_variance   | 0.736         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 820           |\n",
      "|    policy_gradient_loss | 0.000598      |\n",
      "|    value_loss           | 2.49e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 55.2          |\n",
      "|    ep_rew_mean          | 240           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 3386          |\n",
      "|    total_timesteps      | 196608        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057987194 |\n",
      "|    clip_fraction        | 0.0129        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.0853       |\n",
      "|    explained_variance   | 0.719         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.83e+03      |\n",
      "|    n_updates            | 830           |\n",
      "|    policy_gradient_loss | 0.000392      |\n",
      "|    value_loss           | 2.7e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 57.6         |\n",
      "|    ep_rew_mean          | 263          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 3525         |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003070329 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.0755      |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 953          |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | 0.000387     |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x29751746e30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difficulty = 5\n",
    "\n",
    "env = ViZDoomGym(config=f'doom/corridor_schedule/deadly_corridor_s{difficulty}.cfg')\n",
    "callback = TrainAndLoggingCallback(check_freq=33333, save_path=CHECKPOINT_DIR + f'/s{difficulty}')\n",
    " \n",
    "model = PPO.load(CHECKPOINT_DIR + '/s3' + '/best_model_199998.zip', env=env, device='cuda')\n",
    "model.learn(total_timesteps=200000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(CHECKPOINT_DIR + '/s5' + '/best_model_199998')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ViZDoomGym(render=True, config='doom/corridor_schedule/deadly_corridor_s1.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\phiga\\Documents\\GitHub\\RL-experminents\\doom_corridor.ipynb Zelle 33\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000032?line=0'>1</a>\u001b[0m mean_reward, _ \u001b[39m=\u001b[39m evaluate_policy(model, env, n_eval_episodes\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000032?line=1'>2</a>\u001b[0m mean_reward\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_policy' is not defined"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.78125\n",
      "1.4892578125\n",
      "2.130889892578125\n",
      "2.7123565673828125\n",
      "3.23931884765625\n",
      "3.7168731689453125\n",
      "4.149658203125\n",
      "4.5418701171875\n",
      "4.897308349609375\n",
      "5.21942138671875\n",
      "5.5113372802734375\n",
      "5.7758941650390625\n",
      "6.0156402587890625\n",
      "6.23291015625\n",
      "6.4298248291015625\n",
      "6.6082763671875\n",
      "6.769989013671875\n",
      "6.9165496826171875\n",
      "7.0493621826171875\n",
      "7.1697235107421875\n",
      "7.27880859375\n",
      "7.3776702880859375\n",
      "7.467254638671875\n",
      "7.5484466552734375\n",
      "7.6220245361328125\n",
      "7.6887054443359375\n",
      "7.7491302490234375\n",
      "7.80389404296875\n",
      "7.853515625\n",
      "7.89849853515625\n",
      "7.9392547607421875\n",
      "7.9761962890625\n",
      "8.009674072265625\n",
      "8.040008544921875\n",
      "8.0675048828125\n",
      "8.092422485351562\n",
      "8.115005493164062\n",
      "8.135467529296875\n",
      "8.154006958007812\n",
      "8.170806884765625\n",
      "8.18603515625\n",
      "8.199844360351562\n",
      "8.212356567382812\n",
      "8.22369384765625\n",
      "8.233963012695312\n",
      "8.243270874023438\n",
      "8.251708984375\n",
      "8.259353637695312\n",
      "8.266281127929688\n",
      "8.272552490234375\n",
      "8.278244018554688\n",
      "8.283401489257812\n",
      "8.288070678710938\n",
      "8.292312622070312\n",
      "8.296157836914062\n",
      "8.299636840820312\n",
      "8.30279541015625\n",
      "8.305648803710938\n",
      "8.308242797851562\n",
      "8.310592651367188\n",
      "8.312713623046875\n",
      "8.31463623046875\n",
      "8.316375732421875\n",
      "8.317962646484375\n",
      "8.31939697265625\n",
      "8.320693969726562\n",
      "8.321868896484375\n",
      "8.32293701171875\n",
      "8.323898315429688\n",
      "8.32476806640625\n",
      "8.3255615234375\n",
      "8.326278686523438\n",
      "8.326934814453125\n",
      "8.327529907226562\n",
      "8.32806396484375\n",
      "8.32855224609375\n",
      "8.328994750976562\n",
      "8.329391479492188\n",
      "8.329757690429688\n",
      "-31.669921875\n",
      "8.007980346679688\n",
      "8.038467407226562\n",
      "8.06610107421875\n",
      "-21.908859252929688\n",
      "8.227294921875\n",
      "8.237228393554688\n",
      "8.246231079101562\n",
      "8.25439453125\n",
      "-21.738204956054688\n",
      "8.7008056640625\n",
      "8.666351318359375\n",
      "8.635116577148438\n",
      "8.6068115234375\n",
      "8.581161499023438\n",
      "8.55792236328125\n",
      "8.27008056640625\n",
      "7.8605804443359375\n",
      "-52.09510803222656\n",
      "8.926788330078125\n",
      "8.86822509765625\n",
      "8.818069458007812\n",
      "-31.227386474609375\n",
      "9.327835083007812\n",
      "9.013580322265625\n",
      "8.949798583984375\n",
      "8.891998291015625\n",
      "-31.160385131835938\n",
      "9.421463012695312\n",
      "9.256103515625\n",
      "9.169586181640625\n",
      "9.0911865234375\n",
      "9.020126342773438\n",
      "8.955734252929688\n",
      "8.897369384765625\n",
      "8.844482421875\n",
      "8.796554565429688\n",
      "8.75311279296875\n",
      "8.7137451171875\n",
      "8.678070068359375\n",
      "8.645736694335938\n",
      "8.616439819335938\n",
      "8.589889526367188\n",
      "8.565826416015625\n",
      "8.544021606445312\n",
      "258.5242614746094\n",
      "8.50634765625\n",
      "8.490127563476562\n",
      "8.475418090820312\n",
      "8.46209716796875\n",
      "8.45001220703125\n",
      "8.439071655273438\n",
      "8.429153442382812\n",
      "8.420166015625\n",
      "8.412017822265625\n",
      "8.404632568359375\n",
      "8.397933959960938\n",
      "8.391876220703125\n",
      "8.386383056640625\n",
      "8.38140869140625\n",
      "8.37689208984375\n",
      "8.372802734375\n",
      "8.369094848632812\n",
      "8.365737915039062\n",
      "8.362686157226562\n",
      "-61.64007568359375\n",
      "9.697372436523438\n",
      "9.569488525390625\n",
      "9.453598022460938\n",
      "9.34857177734375\n",
      "9.253387451171875\n",
      "9.167129516601562\n",
      "9.088958740234375\n",
      "9.018112182617188\n",
      "8.953903198242188\n",
      "8.895721435546875\n",
      "8.842987060546875\n",
      "8.795196533203125\n",
      "8.75189208984375\n",
      "8.712646484375\n",
      "1008.6770782470703\n",
      "0\n",
      "Reward of episode 1 is 2219.322982788086\n",
      "60.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.78125\n",
      "1.4892578125\n",
      "2.130889892578125\n",
      "2.7123565673828125\n",
      "3.23931884765625\n",
      "3.7168731689453125\n",
      "4.149658203125\n",
      "4.5418701171875\n",
      "4.897308349609375\n",
      "5.21942138671875\n",
      "5.5113372802734375\n",
      "5.7758941650390625\n",
      "6.0156402587890625\n",
      "6.23291015625\n",
      "6.4298248291015625\n",
      "6.6082763671875\n",
      "6.769989013671875\n",
      "6.9165496826171875\n",
      "7.0493621826171875\n",
      "7.1697235107421875\n",
      "7.27880859375\n",
      "7.3776702880859375\n",
      "7.467254638671875\n",
      "7.5484466552734375\n",
      "7.6220245361328125\n",
      "7.6887054443359375\n",
      "7.7491302490234375\n",
      "7.80389404296875\n",
      "7.853515625\n",
      "7.89849853515625\n",
      "7.9392547607421875\n",
      "7.9761962890625\n",
      "8.009674072265625\n",
      "8.040008544921875\n",
      "8.0675048828125\n",
      "8.092422485351562\n",
      "8.115005493164062\n",
      "8.135467529296875\n",
      "8.154006958007812\n",
      "8.170806884765625\n",
      "8.18603515625\n",
      "8.199844360351562\n",
      "8.212356567382812\n",
      "8.22369384765625\n",
      "8.233963012695312\n",
      "8.243270874023438\n",
      "8.251708984375\n",
      "8.259353637695312\n",
      "8.266281127929688\n",
      "8.272552490234375\n",
      "8.278244018554688\n",
      "8.283401489257812\n",
      "8.288070678710938\n",
      "-131.7076873779297\n",
      "11.643844604492188\n",
      "11.333480834960938\n",
      "11.052215576171875\n",
      "10.797317504882812\n",
      "10.566314697265625\n",
      "10.356964111328125\n",
      "10.167236328125\n",
      "9.99530029296875\n",
      "9.8394775390625\n",
      "9.698272705078125\n",
      "9.570297241210938\n",
      "9.454330444335938\n",
      "9.349227905273438\n",
      "9.253982543945312\n",
      "9.16766357421875\n",
      "9.089431762695312\n",
      "9.018539428710938\n",
      "8.954299926757812\n",
      "8.896072387695312\n",
      "8.843307495117188\n",
      "8.795486450195312\n",
      "8.752151489257812\n",
      "8.712875366210938\n",
      "8.677291870117188\n",
      "8.645034790039062\n",
      "8.615798950195312\n",
      "8.589309692382812\n",
      "8.5653076171875\n",
      "8.543548583984375\n",
      "8.523834228515625\n",
      "8.505966186523438\n",
      "8.489776611328125\n",
      "8.47509765625\n",
      "8.461807250976562\n",
      "8.449752807617188\n",
      "8.438827514648438\n",
      "-1.571075439453125\n",
      "8.642562866210938\n",
      "8.613571166992188\n",
      "8.587295532226562\n",
      "-61.4365234375\n",
      "10.17413330078125\n",
      "10.001556396484375\n",
      "9.84515380859375\n",
      "9.703414916992188\n",
      "-20.425033569335938\n",
      "10.176742553710938\n",
      "10.003921508789062\n",
      "9.8472900390625\n",
      "9.705352783203125\n",
      "9.57672119140625\n",
      "9.46014404296875\n",
      "9.3544921875\n",
      "9.258758544921875\n",
      "259.1719970703125\n",
      "9.093368530273438\n",
      "9.022109985351562\n",
      "8.957534790039062\n",
      "8.899002075195312\n",
      "8.845962524414062\n",
      "8.797897338867188\n",
      "8.75433349609375\n",
      "8.714859008789062\n",
      "8.6790771484375\n",
      "8.646652221679688\n",
      "8.617263793945312\n",
      "8.59063720703125\n",
      "8.566513061523438\n",
      "7.763397216796875\n",
      "7.8164215087890625\n",
      "7.864471435546875\n",
      "7.127166748046875\n",
      "7.23870849609375\n",
      "7.3397979736328125\n",
      "7.4314117431640625\n",
      "7.514434814453125\n",
      "7.5896759033203125\n",
      "7.657867431640625\n",
      "7.71966552734375\n",
      "7.775665283203125\n",
      "7.826416015625\n",
      "7.872406005859375\n",
      "7.9140777587890625\n",
      "7.95184326171875\n",
      "7.9860687255859375\n",
      "8.01708984375\n",
      "8.045211791992188\n",
      "8.070693969726562\n",
      "8.093780517578125\n",
      "8.114700317382812\n",
      "8.1336669921875\n",
      "8.150848388671875\n",
      "8.166427612304688\n",
      "8.1805419921875\n",
      "8.193328857421875\n",
      "8.204925537109375\n",
      "8.215423583984375\n",
      "8.224945068359375\n",
      "8.233566284179688\n",
      "8.241378784179688\n",
      "8.248458862304688\n",
      "8.2548828125\n",
      "8.260711669921875\n",
      "1008.2659912109375\n",
      "0\n",
      "Reward of episode 2 is 2342.708297729492\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.78125\n",
      "1.4892578125\n",
      "2.130889892578125\n",
      "2.7123565673828125\n",
      "3.23931884765625\n",
      "3.7168731689453125\n",
      "3.368408203125\n",
      "3.833465576171875\n",
      "4.2549285888671875\n",
      "4.636871337890625\n",
      "4.9830169677734375\n",
      "5.2967071533203125\n",
      "5.58099365234375\n",
      "5.838623046875\n",
      "6.0720977783203125\n",
      "6.28369140625\n",
      "6.4754486083984375\n",
      "6.6492156982421875\n",
      "6.80670166015625\n",
      "6.9494171142578125\n",
      "7.0787506103515625\n",
      "7.1959686279296875\n",
      "7.30218505859375\n",
      "7.3984527587890625\n",
      "7.485687255859375\n",
      "7.5647430419921875\n",
      "7.6363983154296875\n",
      "7.701324462890625\n",
      "7.7601776123046875\n",
      "7.813507080078125\n",
      "7.8618316650390625\n",
      "7.9056243896484375\n",
      "7.9453125\n",
      "7.981292724609375\n",
      "8.013885498046875\n",
      "8.043426513671875\n",
      "8.070205688476562\n",
      "8.094467163085938\n",
      "8.116455078125\n",
      "8.136383056640625\n",
      "8.154449462890625\n",
      "8.170822143554688\n",
      "8.185653686523438\n",
      "8.1990966796875\n",
      "8.211273193359375\n",
      "8.222305297851562\n",
      "8.232315063476562\n",
      "8.241378784179688\n",
      "8.249588012695312\n",
      "8.257034301757812\n",
      "8.263778686523438\n",
      "8.2698974609375\n",
      "8.275436401367188\n",
      "-131.71954345703125\n",
      "11.66387939453125\n",
      "11.351242065429688\n",
      "11.067901611328125\n",
      "10.811126708984375\n",
      "10.57843017578125\n",
      "10.3675537109375\n",
      "10.176437377929688\n",
      "10.00323486328125\n",
      "9.846282958984375\n",
      "9.70404052734375\n",
      "9.57513427734375\n",
      "9.45831298828125\n",
      "9.352447509765625\n",
      "9.256500244140625\n",
      "9.1695556640625\n",
      "9.09075927734375\n",
      "9.01934814453125\n",
      "8.954635620117188\n",
      "8.895980834960938\n",
      "8.84283447265625\n",
      "8.794662475585938\n",
      "8.751007080078125\n",
      "8.711441040039062\n",
      "8.675582885742188\n",
      "8.643096923828125\n",
      "8.6136474609375\n",
      "8.586959838867188\n",
      "8.562774658203125\n",
      "8.540863037109375\n",
      "8.52099609375\n",
      "8.503005981445312\n",
      "8.4866943359375\n",
      "8.471908569335938\n",
      "8.458511352539062\n",
      "8.446365356445312\n",
      "8.43536376953125\n",
      "-1.5746002197265625\n",
      "8.614974975585938\n",
      "8.588165283203125\n",
      "8.563873291015625\n",
      "-61.45814514160156\n",
      "10.039199829101562\n",
      "9.878875732421875\n",
      "9.73358154296875\n",
      "9.601898193359375\n",
      "-21.93560791015625\n",
      "3.342437744140625\n",
      "3.8099365234375\n",
      "4.2335968017578125\n",
      "-65.38246154785156\n",
      "6.59625244140625\n",
      "6.758697509765625\n",
      "6.905914306640625\n",
      "7.039337158203125\n",
      "7.160247802734375\n",
      "7.2698211669921875\n",
      "7.3691253662109375\n",
      "7.4591217041015625\n",
      "-62.459320068359375\n",
      "9.29193115234375\n",
      "9.20166015625\n",
      "9.119857788085938\n",
      "9.04571533203125\n",
      "8.978530883789062\n",
      "8.638946533203125\n",
      "5.6945037841796875\n",
      "2.4229888916015625\n",
      "-37.117645263671875\n",
      "4.3494873046875\n",
      "4.574981689453125\n",
      "4.770477294921875\n",
      "4.9420013427734375\n",
      "5.0925140380859375\n",
      "5.22454833984375\n",
      "-4.6595916748046875\n",
      "5.4517974853515625\n",
      "-4.4572601318359375\n",
      "5.985107421875\n",
      "6.01092529296875\n",
      "6.030364990234375\n",
      "6.04742431640625\n",
      "6.0623931884765625\n",
      "6.0755157470703125\n",
      "6.0870361328125\n",
      "6.097137451171875\n",
      "6.1060028076171875\n",
      "6.1137847900390625\n",
      "6.12060546875\n",
      "6.1266021728515625\n",
      "6.1318511962890625\n",
      "6.136474609375\n",
      "6.1405181884765625\n",
      "6.1440582275390625\n",
      "6.1471710205078125\n",
      "6.14990234375\n",
      "6.1522979736328125\n",
      "6.1544036865234375\n",
      "-33.84375\n",
      "7.2158355712890625\n",
      "7.3201904296875\n",
      "7.414764404296875\n",
      "0\n",
      "Reward of episode 3 is 636.6546020507812\n",
      "490.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.78125\n",
      "1.4892578125\n",
      "2.130889892578125\n",
      "2.7123565673828125\n",
      "3.23931884765625\n",
      "3.7168731689453125\n",
      "4.149658203125\n",
      "4.5418701171875\n",
      "4.897308349609375\n",
      "5.21942138671875\n",
      "5.5113372802734375\n",
      "5.7758941650390625\n",
      "6.0156402587890625\n",
      "6.23291015625\n",
      "6.4298248291015625\n",
      "6.6082763671875\n",
      "6.769989013671875\n",
      "6.9165496826171875\n",
      "7.0493621826171875\n",
      "7.1697235107421875\n",
      "7.27880859375\n",
      "7.3776702880859375\n",
      "7.467254638671875\n",
      "7.5484466552734375\n",
      "7.6220245361328125\n",
      "7.6887054443359375\n",
      "7.7491302490234375\n",
      "7.80389404296875\n",
      "7.853515625\n",
      "7.89849853515625\n",
      "7.9392547607421875\n",
      "-142.0238037109375\n",
      "9.579116821289062\n",
      "9.462310791015625\n",
      "9.356460571289062\n",
      "9.260528564453125\n",
      "9.173599243164062\n",
      "8.810577392578125\n",
      "1.56500244140625\n",
      "2.19952392578125\n",
      "2.774566650390625\n",
      "3.2957000732421875\n",
      "3.767974853515625\n",
      "4.1959686279296875\n",
      "4.583831787109375\n",
      "4.935333251953125\n",
      "5.2538909912109375\n",
      "5.5425872802734375\n",
      "5.8042144775390625\n"
     ]
    },
    {
     "ename": "ViZDoomUnexpectedExitException",
     "evalue": "Controlled ViZDoom instance exited unexpectedly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mViZDoomUnexpectedExitException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\phiga\\Documents\\GitHub\\RL-experminents\\doom_corridor.ipynb Zelle 34\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000033?line=4'>5</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000033?line=5'>6</a>\u001b[0m     action, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000033?line=6'>7</a>\u001b[0m     obs, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000033?line=7'>8</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000033?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(reward)\n",
      "\u001b[1;32mc:\\Users\\phiga\\Documents\\GitHub\\RL-experminents\\doom_corridor.ipynb Zelle 34\u001b[0m in \u001b[0;36mViZDoomGym.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000033?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000033?line=22'>23</a>\u001b[0m     actions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39midentity(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_nr, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000033?line=23'>24</a>\u001b[0m     movement_reward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgame\u001b[39m.\u001b[39;49mmake_action(actions[action])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000033?line=25'>26</a>\u001b[0m     reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phiga/Documents/GitHub/RL-experminents/doom_corridor.ipynb#ch0000033?line=26'>27</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame\u001b[39m.\u001b[39mget_state(): \u001b[39m# interesting line\u001b[39;00m\n",
      "\u001b[1;31mViZDoomUnexpectedExitException\u001b[0m: Controlled ViZDoom instance exited unexpectedly."
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(1/20)\n",
    "        print(reward)\n",
    "        total_reward += reward\n",
    "    print(f'Reward of episode {episode+1} is {total_reward}')\n",
    "    time.sleep(2)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not perfoect performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reinforcement')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4984e7ba3fca0e09acc1abfa4e61dc59df22bf9db11b60a1a72c49fd6cc05221"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
